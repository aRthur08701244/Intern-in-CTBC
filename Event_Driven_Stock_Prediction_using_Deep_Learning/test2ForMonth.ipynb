#!/usr/bin/python
import json
import os
# import en
import datetime
import nltk
import numpy as np
import pandas as pd
from wakepy import set_keepawake, unset_keepawake
import shutil
import time

##### !!! NOTICE: input1為初版沒有考慮company embedding !!! #####

set_keepawake(keep_screen_awake=True)

def dateGenerator(numdays): # generate N days until now, eg [20151231, 20151230]
    base = datetime.datetime.today()
    date_list = [base - datetime.timedelta(days=x) for x in range(0, numdays)]
    for i in range(len(date_list)): date_list[i] = date_list[i].strftime("%Y%m%d")
    return set(date_list)

def unify_word(word): 
    return word.lower()

def readGlove(we_file):
    wordVec = np.zeros([0,100])
    with open(we_file) as file:
        for line in file:
            line = line.strip().split()
            line = list(map(float,line))
            wordVec = np.vstack((wordVec,np.array(line).flatten()))
    return wordVec

def padding(sentencesVec, keepNum):
    shape = sentencesVec.shape[0]
    ownLen = sentencesVec.shape[1]
    if ownLen < keepNum:
        return np.hstack((np.zeros([shape, keepNum-ownLen]), sentencesVec)).flatten()
    else:
        return sentencesVec[:, -keepNum:].flatten()

def gen_FeatureMatrix(wordEmbedding, word2idx, priceDt, max_words=60, mtype="test"):
    set_keepawake(keep_screen_awake=True)
    # step 2, build feature matrix for training data
    loc = './input2/WB_TransNews/'
    if mtype == 'train': loc += 'train/'
    if mtype == 'validation': loc += 'valid/'
    if mtype == 'test': loc += 'test/'
    input_files = [f for f in os.listdir(loc) if f.endswith('cnyesnews.csv')]

    cnt = 0

    for i in range(len(input_files)):
        file = input_files[i]
        gap_year = ''
        if i != (len(input_files)-1):
            next_file = input_files[i+1]
        else:
            next_file = input_files[i]
        
        this_year = file.split('_')[0][0:4]
        gap_year = min([file.split('_')[0][0:4], next_file.split('_')[0][0:4]])

        print(file.split('_')[0][0:4])
        count = 0 # Not more than 50k news

        news = pd.read_csv(loc+file)

        for i in news.index:

            if len(news.iloc[i].values) != 4: continue

            day, all, tokens, ticker = news.iloc[i].values
            day = str(day)

            if ticker not in priceDt: continue 

            if day not in priceDt[ticker].keys(): continue

            cnt += 1

            if (cnt%1000) == 0:
                try:
                    fileName = './input2/stockFeatures_ForCNN/featureMatrix_' + str(cnt//1000) + "_" + mtype + '.csv'
                    fileName2 = './input2/stockFeatures_ForCNN/featureMatrix_' + this_year + str(cnt//1000) + "_" + mtype + '.csv'
                    
                    print(fileName.split('_')[-2:], 'to', this_year)

                    shutil.move(fileName, fileName2)
                except:
                    print('Not Here')
            
            if i == news.index[-1]:
                try:
                    print('Last News')
                    fileName = './input2/stockFeatures_ForCNN/featureMatrix_' + str(cnt//1000) + "_" + mtype + '.csv'
                    fileName2 = './input2/stockFeatures_ForCNN/featureMatrix_' + this_year + str(cnt//1000) + "_" + mtype + '.csv'
                    
                    print(fileName.split('_')[-2:], 'to', gap_year)

                    shutil.move(fileName, fileName2)
                except:
                    print('Not Here')

    fileName = './input2/stockFeatures_ForCNN/featureMatrix_' + str(cnt//1000+1) + "_" + mtype + '.csv'
    print(fileName.split('_')[-2:])

    set_keepawake(keep_screen_awake=False)

def build(wordEmbedding, w2i_file, max_words=60):
    with open('./input2/stockReturns.json') as data_file:
        priceDt = json.load(data_file)
    with open(w2i_file) as data_file:
        word2idx = json.load(data_file)

    gen_FeatureMatrix(wordEmbedding, word2idx, priceDt, max_words, "train")
    # gen_FeatureMatrix(wordEmbedding, word2idx, priceDt, max_words, "validation")
    # gen_FeatureMatrix(wordEmbedding, word2idx, priceDt, max_words, "test")

def main(we, w2i_file):
    wordEmbedding = readGlove(we)
    build(wordEmbedding, w2i_file, 30)


if __name__ == "__main__":
    we = './input2/wordEmbeddingsVocab.csv'
    w2i_file = "./input2/word2idx.json"
    main(we, w2i_file)
    set_keepawake(keep_screen_awake=False)


